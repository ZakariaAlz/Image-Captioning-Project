# **ğŸ“¸ Image Captioning Using Deep Learning**

## ğŸŒŸ **Overview**
This project integrates three deliverables to build a comprehensive pipeline for image analysis and caption generation:
1. **Binary Classification**: ğŸ¾ Distinguish photos from other image types.
2. **Image Denoising**: ğŸ–Œï¸ Enhance image quality using convolutional autoencoders.
3. **Image Captioning**: ğŸ“ Generate descriptive captions for images using a CNN-RNN pipeline.


âœ¨ Features
1. ğŸ“‹ Binary Classification: Identifies photos from other types of images (paintings, sketches, etc.).
2. âœ¨ Image Denoising: Improves the quality of noisy images using convolutional autoencoders.
3. ğŸ–¼ï¸ Image Captioning:
   - Generates captions for images using a CNN-RNN pipeline.
   - Includes an attention mechanism for enhanced performance.
---

## **Deliverables**

### **Deliverable 1: Binary Classification**
- **Objective**: Identify photos from other types of images (paintings, sketches, etc.).
- **Methodology**:
  - Preprocess and normalize the dataset.
  - Build a Convolutional Neural Network (CNN) for classification.
  - Train and evaluate the model using training and validation data.
- **Results**:
  - Validation Accuracy: **72%**
  - Sample Predictions: Correctly identifies photos among other image types.

---

### **Deliverable 2: Image Denoising**
- **Objective**: Remove noise from images using an autoencoder.
- **Methodology**:
  - Add Gaussian noise to the dataset.
  - Train a convolutional autoencoder to reconstruct clean images from noisy inputs.
- **Results**:
  - High-quality denoised images demonstrated through visual comparisons.

---

### **Deliverable 3: Image Captioning**
- **Objective**: Generate captions for images using a deep learning model.
- **Methodology**:
  - Use a pre-trained CNN (InceptionV3) to extract image features.
  - Use a Recurrent Neural Network (RNN) to predict captions from the image features.
  - Train the model and evaluate its performance using BLEU scores.
- **Results**:
  - Sample Caption: **"A cat sitting on a couch."**
  - High BLEU scores indicating strong performance.

---

## **Technology Stack**
- ğŸ“œ **Languages**: Python
- ğŸ§  **Deep Learning Frameworks**: TensorFlow, Keras
- ğŸ“¦ **Tools**: NumPy, Matplotlib, Pillow
- ğŸ” **Pre-trained Models**:
  - InceptionV3 (for feature extraction)
  - GRU-based RNN (for text generation)
 
 ## ğŸ“‚ **Dataset**
The Deliverable 1&2 have separated datasets, deliverable 3 uses the MS COCO Dataset ğŸ¤, a widely adopted benchmark for image captioning tasks. It contains:
Source: MS COCO Dataset
### Description:
ğŸ–¼ï¸ Images with corresponding captions.
ğŸ“ Multiple annotations per image.
#### Additional Notes:
During the technical presentation, a secondary dataset was provided to test the robustness of the pipeline.


---

## ğŸš€ How to Run the Project
 ### 1. ğŸ“¥ Clone the Repository: 
   git clone https://github.com/ZakariaAlz/Image-Captioning-Project.git 
   cd image-captioning-deep-learning

 ### 2. ğŸ“¦ Install Dependencies
   Make sure you have Python 3.8+ installed. Then, run:
   pip install -r requirements.txt


 ### 3. ğŸ”„ Preprocess the Dataset
   Place the MS COCO dataset in the data/ directory.
   Run the preprocessing script:
   python preprocess.py


 ### 4. ğŸ‹ï¸ Train the Model
   To train the captioning model:
   python preprocess.py

 ### 5. ğŸ§ª Evaluate and Generate Captions
Evaluate the model on the test set and generate captions:
python evaluate.py

## ğŸ–¼ï¸ Sample Results
Input Image
Generated Caption

Example: ğŸˆ A cat sitting on a couch.

### ğŸ¤ Contributors
 ğŸ‘¨â€ğŸ’» Zakaria ALIZOUAOUI: Model development and evaluation.
 ğŸ” Yacine BABACI: Dataset preprocessing and pipeline optimization.
 ğŸ“Š Ali MAHDJOUB: Integration and visualizations.

##ğŸ“œ License
 This project is licensed under the MIT License.
